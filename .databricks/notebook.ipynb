{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook\n",
    "import requests\n",
    "from pyspark.sql.functions import current_timestamp, from_json, explode\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, TimestampType\n",
    "\n",
    "# FastAPI endpoint URLs\n",
    "FASTAPI_BASE_URL = \"https://hushed-dolphin-894.convex.site\"  # Replace with your actual FastAPI URL\n",
    "EMAILS_ENDPOINT = f\"{FASTAPI_BASE_URL}/email\"\n",
    "USER_IDS_ENDPOINT = f\"{FASTAPI_BASE_URL}/list\"\n",
    "USER_DETAILS_ENDPOINT = f\"{FASTAPI_BASE_URL}/emailuserlist\"\n",
    "MESSAGES_ENDPOINT = f\"{FASTAPI_BASE_URL}/messages\"\n",
    "\n",
    "# Fetch data from FastAPI endpoints\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Create DataFrames and save as Delta tables\n",
    "def ingest_data():\n",
    "    # Emails\n",
    "    emails_data = fetch_data(EMAILS_ENDPOINT)\n",
    "    emails_df = spark.createDataFrame([(email,) for email in emails_data], [\"email\"])\n",
    "    emails_df = emails_df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    emails_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"emails\")\n",
    "\n",
    "    # User IDs\n",
    "    user_ids_data = fetch_data(USER_IDS_ENDPOINT)\n",
    "    user_ids_df = spark.createDataFrame([(user_id,) for user_id in user_ids_data], [\"user_id\"])\n",
    "    user_ids_df = user_ids_df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    user_ids_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"user_ids\")\n",
    "\n",
    "    # User Details\n",
    "    user_details_data = fetch_data(USER_DETAILS_ENDPOINT)\n",
    "    user_details_schema = StructType([\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"id\", StringType(), True)\n",
    "    ])\n",
    "    user_details_df = spark.createDataFrame(user_details_data, schema=user_details_schema)\n",
    "    user_details_df = user_details_df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    user_details_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"user_details\")\n",
    "\n",
    "    # Messages\n",
    "    messages_data = fetch_data(MESSAGES_ENDPOINT)\n",
    "    message_schema = StructType([\n",
    "        StructField(\"_id\", StringType(), True),\n",
    "        StructField(\"_creationTime\", StringType(), True),\n",
    "        StructField(\"meetupChatId\", StringType(), True),\n",
    "        StructField(\"senderId\", StringType(), True),\n",
    "        StructField(\"message\", StringType(), True)\n",
    "    ])\n",
    "    messages_df = spark.createDataFrame(messages_data, schema=message_schema)\n",
    "    messages_df = messages_df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    messages_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"messages\")\n",
    "\n",
    "# Run the ingestion\n",
    "ingest_data()\n",
    "\n",
    "print(\"Data ingestion completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
